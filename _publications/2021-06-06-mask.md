---
title: "Wearing A Mask: Compressed Representations of Variable-Length Sequences Using Recurrent Neural Tangent Kernels"
authors: S. Alemohammad, H. Babaei, R. Balestriero, M.Y. Cheung, A.I. Humayun, D. LeJeune, N. Liu, L. Luzi, <b>J. Tan</b>, Z. Wang, R.G. Baraniuk
collection: publications
excerpt: 'Using the recurrent neural tangent kernel to perform kernel-based dimensionality reduction on variable-length signals/sequences'
date: 2021-06-06
venue: 'IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'
paperurl: 'https://ieeexplore.ieee.org/document/9413450'
code: 'https://github.com/dlej/MASK'
---
**Abstract:** 
High dimensionality poses many challenges to the use of data, from visualization and interpretation, to prediction and storage for historical preservation. Techniques abound to reduce the dimensionality of fixed-length sequences, yet these methods rarely generalize to variable-length sequences. To address this gap, we extend existing methods that rely on the use of kernels to variable-length sequences via use of the Recurrent Neural Tangent Kernel (RNTK). Since a deep neural network with ReLu activation is a Max-Affine Spline Operator (MASO), we dub our approach Max-Affine Spline Kernel (MASK). We demonstrate how MASK can be used to extend principal components analysis (PCA) and t-distributed stochastic neighbor embedding (t-SNE) and apply these new algorithms to separate synthetic time series data sampled from second-order differential equations.

**Links:**
[Paper](https://ieeexplore.ieee.org/document/9413450) | [Code](https://github.com/dlej/MASK)
